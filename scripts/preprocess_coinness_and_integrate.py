"""
ì½”ì¸ë‰´ìŠ¤(Coinness) ë°ì´í„° ì „ì²˜ë¦¬ ë° í†µí•© ë¶„ì„

ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ì‹œê°„ë³„ë¡œ ì§‘ê³„í•˜ê³  ê°ì • ë¶„ì„ í›„
ê¸°ì¡´ ë‹¤ì¤‘ ì†ŒìŠ¤ ë°ì´í„°(í…”ë ˆê·¸ë¨, ê³ ë˜, íŠ¸ìœ„í„°, ê°€ê²©)ì™€ í†µí•©
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')


class CoinnessPreprocessor:
    """ì½”ì¸ë‰´ìŠ¤ ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, news_path):
        """
        Args:
            news_path: ì½”ì¸ë‰´ìŠ¤ CSV ê²½ë¡œ
        """
        print("=" * 80)
        print("ì½”ì¸ë‰´ìŠ¤ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘")
        print("=" * 80)
        
        self.news_df = pd.read_csv(news_path)
        print(f"\nâœ“ ì›ë³¸ ë°ì´í„° ë¡œë“œ: {len(self.news_df)} rows")
        
    def preprocess_news(self):
        """ë‰´ìŠ¤ ë°ì´í„° ì „ì²˜ë¦¬"""
        print("\në°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        
        df = self.news_df.copy()
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ë³€í™˜
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        
        # ì¤‘ë³µ ì œê±° (ë™ì¼ ì‹œê°„ + ë™ì¼ ì œëª©)
        original_len = len(df)
        df = df.drop_duplicates(subset=['timestamp', 'title'], keep='first')
        print(f"  - ì¤‘ë³µ ì œê±°: {original_len} â†’ {len(df)} ({original_len - len(df)}ê°œ ì œê±°)")
        
        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        df['content'] = df['content'].fillna('')
        df['title'] = df['title'].fillna('')
        
        # ê°ì • ì ìˆ˜ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (0ìœ¼ë¡œ)
        sentiment_cols = ['sentiment_compound', 'sentiment_positive', 
                         'sentiment_negative', 'sentiment_neutral']
        for col in sentiment_cols:
            if col in df.columns:
                df[col] = df[col].fillna(0)
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ ê³„ì‚°
        df['title_length'] = df['title'].str.len()
        df['content_length'] = df['content'].str.len()
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë²„ì „)
        df['has_bitcoin'] = df['title'].str.contains('ë¹„íŠ¸ì½”ì¸|BTC|bitcoin', case=False, na=False)
        df['has_ethereum'] = df['title'].str.contains('ì´ë”ë¦¬ì›€|ETH|ethereum', case=False, na=False)
        df['has_altcoin'] = df['title'].str.contains('ì•ŒíŠ¸ì½”ì¸|altcoin|ë¦¬í”Œ|XRP|ë„ì§€|DOGE|ì—ì´ë‹¤|ADA', case=False, na=False)
        df['has_regulation'] = df['title'].str.contains('ê·œì œ|ë²•|ì •ë¶€|SEC|ê¸ˆìœµë‹¹êµ­', case=False, na=False)
        df['has_whale'] = df['title'].str.contains('ê³ ë˜|ëŒ€ê·œëª¨|ë§¤ì§‘', case=False, na=False)
        df['has_bullish'] = df['title'].str.contains('ê¸‰ë“±|ìƒìŠ¹|í­ë“±|ê°•ì„¸|ë¶ˆì¥|ë ë¦¬', case=False, na=False)
        df['has_bearish'] = df['title'].str.contains('ê¸‰ë½|í•˜ë½|í­ë½|ì•½ì„¸|ì•½ì„¸ì¥', case=False, na=False)
        
        print(f"âœ“ ì „ì²˜ë¦¬ ì™„ë£Œ")
        print(f"  - ê¸°ê°„: {df['timestamp'].min()} ~ {df['timestamp'].max()}")
        print(f"  - ë¹„íŠ¸ì½”ì¸ ì–¸ê¸‰: {df['has_bitcoin'].sum()}ê±´")
        print(f"  - ì´ë”ë¦¬ì›€ ì–¸ê¸‰: {df['has_ethereum'].sum()}ê±´")
        print(f"  - ê°•ì„¸ ë‰´ìŠ¤: {df['has_bullish'].sum()}ê±´")
        print(f"  - ì•½ì„¸ ë‰´ìŠ¤: {df['has_bearish'].sum()}ê±´")
        
        self.news_df = df
        return df
    
    def aggregate_hourly(self):
        """ì‹œê°„ë³„ë¡œ ë‰´ìŠ¤ ë°ì´í„° ì§‘ê³„"""
        print("\nì‹œê°„ë³„ ì§‘ê³„ ì¤‘...")
        
        df = self.news_df.copy()
        
        # ì‹œê°„ ë‹¨ìœ„ë¡œ ë°˜ì˜¬ë¦¼
        df['hour'] = df['timestamp'].dt.floor('H')
        
        # ì‹œê°„ë³„ ì§‘ê³„
        hourly = df.groupby('hour').agg({
            'title': 'count',  # ë‰´ìŠ¤ ê°œìˆ˜
            'sentiment_compound': 'mean',  # í‰ê·  ê°ì • ì ìˆ˜
            'sentiment_positive': 'mean',
            'sentiment_negative': 'mean',
            'sentiment_neutral': 'mean',
            'title_length': 'mean',
            'content_length': 'mean',
            'has_bitcoin': 'sum',
            'has_ethereum': 'sum',
            'has_altcoin': 'sum',
            'has_regulation': 'sum',
            'has_whale': 'sum',
            'has_bullish': 'sum',
            'has_bearish': 'sum',
        }).reset_index()
        
        # ì»¬ëŸ¼ëª… ë³€ê²½
        hourly.columns = [
            'timestamp',
            'news_count',
            'news_sentiment_avg',
            'news_positive_avg',
            'news_negative_avg',
            'news_neutral_avg',
            'news_title_length',
            'news_content_length',
            'news_bitcoin_mentions',
            'news_ethereum_mentions',
            'news_altcoin_mentions',
            'news_regulation_mentions',
            'news_whale_mentions',
            'news_bullish_count',
            'news_bearish_count',
        ]
        
        # ê°ì • ë¹„ìœ¨ ê³„ì‚°
        hourly['news_bullish_ratio'] = hourly['news_bullish_count'] / (hourly['news_count'] + 1e-10)
        hourly['news_bearish_ratio'] = hourly['news_bearish_count'] / (hourly['news_count'] + 1e-10)
        
        print(f"âœ“ ì§‘ê³„ ì™„ë£Œ: {len(hourly)} ì‹œê°„")
        print(f"  - ì‹œê°„ë‹¹ í‰ê·  ë‰´ìŠ¤: {hourly['news_count'].mean():.2f}ê±´")
        print(f"  - í‰ê·  ê°ì • ì ìˆ˜: {hourly['news_sentiment_avg'].mean():.4f}")
        
        self.hourly_df = hourly
        return hourly
    
    def save_preprocessed(self, output_path):
        """ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥"""
        # ì›ë³¸ (ì „ì²˜ë¦¬ë¨)
        news_output = output_path.replace('.csv', '_preprocessed.csv')
        self.news_df.to_csv(news_output, index=False)
        print(f"\nâœ“ ì „ì²˜ë¦¬ëœ ë‰´ìŠ¤ ë°ì´í„° ì €ì¥: {news_output}")
        
        # ì‹œê°„ë³„ ì§‘ê³„
        hourly_output = output_path.replace('.csv', '_hourly.csv')
        self.hourly_df.to_csv(hourly_output, index=False)
        print(f"âœ“ ì‹œê°„ë³„ ì§‘ê³„ ë°ì´í„° ì €ì¥: {hourly_output}")
        
        return news_output, hourly_output


class MultiSourceWithNewsIntegrator:
    """ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ê¸°ì¡´ ë‹¤ì¤‘ ì†ŒìŠ¤ì— í†µí•©"""
    
    def __init__(self):
        """ë°ì´í„° ê²½ë¡œ ì„¤ì •"""
        self.base_path = '/Volumes/T7/class/2025-FALL/big_data/data'
        
        print("\n" + "=" * 80)
        print("ë‹¤ì¤‘ ì†ŒìŠ¤ + ë‰´ìŠ¤ ë°ì´í„° í†µí•©")
        print("=" * 80)
    
    def load_existing_data(self):
        """ê¸°ì¡´ í†µí•© ë°ì´í„° (ê°€ê²© í¬í•¨) ë¡œë“œ"""
        print("\nê¸°ì¡´ ë°ì´í„° ë¡œë”© ì¤‘...")
        
        # ê°€ê²© í¬í•¨ ë‹¤ì¤‘ ì†ŒìŠ¤ ë°ì´í„°
        df = pd.read_csv(f'{self.base_path}/multi_source_with_price.csv')
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        
        print(f"âœ“ ê¸°ì¡´ í†µí•© ë°ì´í„°: {len(df)} rows")
        print(f"  ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}")
        
        return df
    
    def merge_with_news(self, existing_df, news_hourly_df):
        """ë‰´ìŠ¤ ë°ì´í„° ë³‘í•©"""
        print("\në‰´ìŠ¤ ë°ì´í„° ë³‘í•© ì¤‘...")
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ í˜•ì‹ í†µì¼
        news_hourly_df['timestamp'] = pd.to_datetime(news_hourly_df['timestamp'])
        
        # ë³‘í•© (left join - ê¸°ì¡´ ë°ì´í„° ê¸°ì¤€)
        merged = existing_df.merge(news_hourly_df, on='timestamp', how='left')
        
        # ë‰´ìŠ¤ê°€ ì—†ëŠ” ì‹œê°„ëŒ€ëŠ” 0ìœ¼ë¡œ ì±„ì›€
        news_cols = [col for col in merged.columns if col.startswith('news_')]
        merged[news_cols] = merged[news_cols].fillna(0)
        
        print(f"âœ“ ë³‘í•© ì™„ë£Œ: {len(merged)} rows, {len(merged.columns)} columns")
        print(f"  ë‰´ìŠ¤ ë°ì´í„°ê°€ ìˆëŠ” ì‹œê°„: {(merged['news_count'] > 0).sum()} ({(merged['news_count'] > 0).sum() / len(merged) * 100:.1f}%)")
        
        return merged
    
    def calculate_combined_metrics(self, df):
        """í†µí•© ì§€í‘œ ê³„ì‚°"""
        print("\ní†µí•© ì§€í‘œ ê³„ì‚° ì¤‘...")
        
        # 1. ì¢…í•© ê°ì • ì§€ìˆ˜ (ê°€ì¤‘ í‰ê· )
        # í…”ë ˆê·¸ë¨, íŠ¸ìœ„í„°, ë‰´ìŠ¤ì˜ ê°ì •ì„ ê°€ì¤‘ í‰ê· 
        sentiment_cols = []
        weights = []
        
        if 'telegram_avg_sentiment' in df.columns:
            sentiment_cols.append('telegram_avg_sentiment')
            weights.append(0.2)
        
        if 'twitter_sentiment' in df.columns:
            sentiment_cols.append('twitter_sentiment')
            weights.append(0.3)
        
        if 'news_sentiment_avg' in df.columns:
            sentiment_cols.append('news_sentiment_avg')
            weights.append(0.5)  # ë‰´ìŠ¤ ê°ì •ì— ê°€ì¥ ë†’ì€ ê°€ì¤‘ì¹˜
        
        if sentiment_cols:
            # ê° ê°ì • ì ìˆ˜ë¥¼ ì •ê·œí™” (-1 ~ 1)
            df['combined_sentiment'] = 0
            total_weight = sum(weights)
            
            for col, weight in zip(sentiment_cols, weights):
                # ê²°ì¸¡ì¹˜ëŠ” 0ìœ¼ë¡œ
                normalized = df[col].fillna(0)
                df['combined_sentiment'] += normalized * (weight / total_weight)
        
        # 2. ì¢…í•© í™œë™ ì§€ìˆ˜
        # ëª¨ë“  ì†ŒìŠ¤ì˜ í™œë™ì„ Z-scoreë¡œ ì •ê·œí™” í›„ í•©ì‚°
        activity_cols = [
            ('telegram_message_count', 0.2),
            ('whale_tx_count', 0.3),
            ('twitter_engagement', 0.2),
            ('news_count', 0.3)
        ]
        
        df['combined_activity'] = 0
        
        for col, weight in activity_cols:
            if col in df.columns:
                # Z-score ì •ê·œí™”
                mean = df[col].mean()
                std = df[col].std()
                if std > 0:
                    zscore = (df[col] - mean) / std
                    df['combined_activity'] += zscore * weight
        
        # 3. ì‹œì¥ ì˜¨ë„ ì§€ìˆ˜ (0~100)
        # ê°•ì„¸ ë‰´ìŠ¤, ê°ì •, ê°€ê²© ë³€í™”, í™œë™ì„ ì¢…í•©
        market_components = []
        
        if 'news_bullish_ratio' in df.columns:
            market_components.append(df['news_bullish_ratio'] * 40)  # 40% ê°€ì¤‘ì¹˜
        
        if 'combined_sentiment' in df.columns:
            # -1~1ì„ 0~30ìœ¼ë¡œ ë³€í™˜
            market_components.append((df['combined_sentiment'] + 1) * 15)  # 30% ê°€ì¤‘ì¹˜
        
        if 'btc_price_change' in df.columns:
            # -10~10%ë¥¼ 0~30ìœ¼ë¡œ ë³€í™˜ (í´ë¦¬í•‘)
            price_norm = df['btc_price_change'].clip(-10, 10)
            market_components.append((price_norm + 10) * 1.5)  # 30% ê°€ì¤‘ì¹˜
        
        if market_components:
            df['market_temperature'] = sum(market_components)
            df['market_temperature'] = df['market_temperature'].clip(0, 100)
        
        print(f"âœ“ í†µí•© ì§€í‘œ ìƒì„±:")
        if 'combined_sentiment' in df.columns:
            print(f"  - ì¢…í•© ê°ì •: {df['combined_sentiment'].mean():.4f} (ë²”ìœ„: {df['combined_sentiment'].min():.2f} ~ {df['combined_sentiment'].max():.2f})")
        if 'combined_activity' in df.columns:
            print(f"  - ì¢…í•© í™œë™: {df['combined_activity'].mean():.4f}")
        if 'market_temperature' in df.columns:
            print(f"  - ì‹œì¥ ì˜¨ë„: {df['market_temperature'].mean():.2f} (0~100)")
        
        return df
    
    def generate_alerts_with_news(self, df):
        """ë‰´ìŠ¤ ê¸°ë°˜ ì¶”ê°€ ì•ŒëŒ ìƒì„±"""
        print("\në‰´ìŠ¤ ê¸°ë°˜ ì•ŒëŒ ìƒì„± ì¤‘...")
        
        alerts = []
        
        for idx, row in df.iterrows():
            alert_reasons = []
            priority = 0
            
            # ë‰´ìŠ¤ ê¸‰ì¦ (ì‹œê°„ë‹¹ 10ê±´ ì´ìƒ)
            if row.get('news_count', 0) >= 10:
                priority += 2
                alert_reasons.append(f"ë‰´ìŠ¤ ê¸‰ì¦ ({row['news_count']:.0f}ê±´)")
            
            # ê°•ì„¸ ë‰´ìŠ¤ ì§‘ì¤‘ (70% ì´ìƒ)
            if row.get('news_bullish_ratio', 0) >= 0.7 and row.get('news_count', 0) >= 3:
                priority += 3
                alert_reasons.append(f"ê°•ì„¸ ë‰´ìŠ¤ ì§‘ì¤‘ ({row['news_bullish_ratio']*100:.0f}%)")
            
            # ì•½ì„¸ ë‰´ìŠ¤ ì§‘ì¤‘ (70% ì´ìƒ)
            if row.get('news_bearish_ratio', 0) >= 0.7 and row.get('news_count', 0) >= 3:
                priority += 3
                alert_reasons.append(f"ì•½ì„¸ ë‰´ìŠ¤ ì§‘ì¤‘ ({row['news_bearish_ratio']*100:.0f}%)")
            
            # ê·œì œ ë‰´ìŠ¤ (3ê±´ ì´ìƒ)
            if row.get('news_regulation_mentions', 0) >= 3:
                priority += 4
                alert_reasons.append(f"ê·œì œ ê´€ë ¨ ë‰´ìŠ¤ ({row['news_regulation_mentions']:.0f}ê±´)")
            
            # ë‰´ìŠ¤ + ê³ ë˜ ê±°ë˜ ë™ì‹œ ê¸‰ì¦
            news_spike = row.get('news_count', 0) >= 8
            whale_spike = row.get('whale_tx_count', 0) > df['whale_tx_count'].quantile(0.95)
            
            if news_spike and whale_spike:
                priority += 5
                alert_reasons.append("âš ï¸ ë‰´ìŠ¤+ê³ ë˜ ë™ì‹œ ê¸‰ì¦")
            
            # ë‰´ìŠ¤ + ê°€ê²© ê¸‰ë³€
            if row.get('news_count', 0) >= 8 and abs(row.get('btc_price_change', 0)) >= 2:
                priority += 4
                alert_reasons.append(f"ë‰´ìŠ¤+ê°€ê²©ê¸‰ë³€ (BTC {row['btc_price_change']:.1f}%)")
            
            if priority >= 4:  # ì¤‘ìš”ë„ 4 ì´ìƒë§Œ ì•ŒëŒ
                level = 'CRITICAL' if priority >= 10 else 'HIGH' if priority >= 6 else 'MEDIUM'
                
                alerts.append({
                    'timestamp': row['timestamp'],
                    'alert_level': level,
                    'priority_score': priority,
                    'reasons': '; '.join(alert_reasons),
                    'news_count': row.get('news_count', 0),
                    'news_sentiment': row.get('news_sentiment_avg', 0),
                    'news_bullish_ratio': row.get('news_bullish_ratio', 0),
                    'btc_price': row.get('btc_close', 0),
                    'btc_change': row.get('btc_price_change', 0),
                })
        
        alerts_df = pd.DataFrame(alerts)
        
        if not alerts_df.empty:
            print(f"âœ“ {len(alerts_df)}ê°œ ì•ŒëŒ ìƒì„±")
            level_counts = alerts_df['alert_level'].value_counts()
            for level, count in level_counts.items():
                print(f"  - {level}: {count}ê°œ")
        else:
            print("âš  ìƒì„±ëœ ì•ŒëŒ ì—†ìŒ")
        
        return alerts_df
    
    def save_integrated_data(self, df, alerts_df):
        """í†µí•© ë°ì´í„° ì €ì¥"""
        print("\n" + "=" * 80)
        print("ê²°ê³¼ ì €ì¥")
        print("=" * 80)
        
        # ìµœì¢… í†µí•© ë°ì´í„°
        output_path = f'{self.base_path}/final_integrated_data.csv'
        df.to_csv(output_path, index=False)
        print(f"âœ“ ìµœì¢… í†µí•© ë°ì´í„°: {output_path}")
        print(f"  - {len(df)} rows Ã— {len(df.columns)} columns")
        
        # ë‰´ìŠ¤ ê¸°ë°˜ ì•ŒëŒ
        if not alerts_df.empty:
            alerts_path = f'{self.base_path}/news_based_alerts.csv'
            alerts_df.to_csv(alerts_path, index=False)
            print(f"âœ“ ë‰´ìŠ¤ ê¸°ë°˜ ì•ŒëŒ: {alerts_path}")
            print(f"  - {len(alerts_df)} alerts")
        
        # ëŒ€ì‹œë³´ë“œìš© ìš”ì•½ í†µê³„
        summary = {
            'total_rows': len(df),
            'date_range': f"{df['timestamp'].min()} ~ {df['timestamp'].max()}",
            'total_news': df['news_count'].sum(),
            'avg_news_per_hour': df['news_count'].mean(),
            'avg_sentiment': df.get('combined_sentiment', pd.Series([0])).mean(),
            'avg_market_temp': df.get('market_temperature', pd.Series([0])).mean(),
            'total_alerts': len(alerts_df) if not alerts_df.empty else 0,
        }
        
        summary_path = f'{self.base_path}/dashboard_summary.json'
        import json
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False, default=str)
        print(f"âœ“ ëŒ€ì‹œë³´ë“œ ìš”ì•½: {summary_path}")
        
        return output_path


if __name__ == '__main__':
    # 1. ë‰´ìŠ¤ ë°ì´í„° ì „ì²˜ë¦¬
    print("\n[STEP 1] ì½”ì¸ë‰´ìŠ¤ ë°ì´í„° ì „ì²˜ë¦¬")
    print("=" * 80)
    
    news_path = '/Volumes/T7/class/2025-FALL/big_data/data/coinness_data2.csv'
    preprocessor = CoinnessPreprocessor(news_path)
    
    # ì „ì²˜ë¦¬
    preprocessor.preprocess_news()
    
    # ì‹œê°„ë³„ ì§‘ê³„
    news_hourly = preprocessor.aggregate_hourly()
    
    # ì €ì¥
    preprocessor.save_preprocessed(news_path)
    
    # 2. ê¸°ì¡´ ë°ì´í„°ì™€ í†µí•©
    print("\n\n[STEP 2] ë‹¤ì¤‘ ì†ŒìŠ¤ ë°ì´í„°ì™€ í†µí•©")
    print("=" * 80)
    
    integrator = MultiSourceWithNewsIntegrator()
    
    # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
    existing_df = integrator.load_existing_data()
    
    # ë‰´ìŠ¤ ë°ì´í„° ë³‘í•©
    integrated_df = integrator.merge_with_news(existing_df, news_hourly)
    
    # í†µí•© ì§€í‘œ ê³„ì‚°
    integrated_df = integrator.calculate_combined_metrics(integrated_df)
    
    # ë‰´ìŠ¤ ê¸°ë°˜ ì•ŒëŒ ìƒì„±
    news_alerts = integrator.generate_alerts_with_news(integrated_df)
    
    # ì €ì¥
    final_path = integrator.save_integrated_data(integrated_df, news_alerts)
    
    print("\n" + "=" * 80)
    print("ì „ì²˜ë¦¬ ë° í†µí•© ì™„ë£Œ! ğŸ‰")
    print("=" * 80)
    print(f"\nëŒ€ì‹œë³´ë“œì—ì„œ ì‚¬ìš©í•  íŒŒì¼:")
    print(f"  1. ìµœì¢… í†µí•© ë°ì´í„°: final_integrated_data.csv")
    print(f"  2. ë‰´ìŠ¤ ê¸°ë°˜ ì•ŒëŒ: news_based_alerts.csv")
    print(f"  3. ëŒ€ì‹œë³´ë“œ ìš”ì•½: dashboard_summary.json")
    print(f"\nì´ì œ Streamlit ëŒ€ì‹œë³´ë“œë¥¼ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”!")

