"""
ì½”ì¸ë‹ˆìŠ¤ í˜ì´ì§€ë„¤ì´ì…˜ ë””ë²„ê¹…
"""

import os
import sys
import time
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup

def find_chromedriver():
    """ChromeDriver ê²½ë¡œ ì°¾ê¸°"""
    paths = [
        '/opt/homebrew/bin/chromedriver',
        '/usr/local/bin/chromedriver',
        '/usr/bin/chromedriver',
    ]
    for path in paths:
        if os.path.exists(path):
            return path
    return None

print("=" * 70)
print("ì½”ì¸ë‹ˆìŠ¤ í˜ì´ì§€ë„¤ì´ì…˜ ë””ë²„ê¹…")
print("=" * 70)

# ChromeDriver ì°¾ê¸°
chromedriver_path = find_chromedriver()
if not chromedriver_path:
    print("âŒ ChromeDriverë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
    sys.exit(1)

print(f"\nâœ“ ChromeDriver: {chromedriver_path}")

# Chrome ì„¤ì •
chrome_options = Options()
chrome_options.add_argument('--headless=new')
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')
chrome_options.binary_location = '/Applications/Google Chrome.app/Contents/MacOS/Google Chrome'

service = Service(executable_path=chromedriver_path)
driver = webdriver.Chrome(service=service, options=chrome_options)

try:
    # í˜ì´ì§€ 1, 2, 3 í…ŒìŠ¤íŠ¸
    for page_num in [1, 2, 3]:
        print(f"\n{'='*70}")
        print(f"í˜ì´ì§€ {page_num} í…ŒìŠ¤íŠ¸")
        print('='*70)
        
        url = f"https://coinness.com/article?page={page_num}"
        print(f"URL: {url}")
        
        driver.get(url)
        
        # ë¡œë”© ëŒ€ê¸°
        try:
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CLASS_NAME, "ArticleWrapper-sc-42qvi5-0"))
            )
        except:
            print("âŒ ArticleWrapper ë¡œë”© ì‹¤íŒ¨")
            continue
        
        time.sleep(2)
        
        # HTML íŒŒì‹±
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        articles = soup.find_all('a', class_=lambda x: x and 'ArticleWrapper' in x)
        
        print(f"ë°œê²¬ëœ ê¸°ì‚¬: {len(articles)}ê°œ")
        
        if articles:
            print(f"\nì²˜ìŒ 3ê°œ ê¸°ì‚¬ ì œëª©:")
            for i, article in enumerate(articles[:3], 1):
                title_elem = article.find('h3', class_=lambda x: x and 'ArticleTitle' in x)
                if title_elem:
                    title = title_elem.get_text(strip=True)
                    print(f"  {i}. {title[:50]}...")
        
        # URLì´ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸
        current_url = driver.current_url
        print(f"\ní˜„ì¬ ë¸Œë¼ìš°ì € URL: {current_url}")
        
        if current_url != url:
            print(f"âš ï¸  URLì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤!")
            print(f"   ìš”ì²­: {url}")
            print(f"   ì‹¤ì œ: {current_url}")

finally:
    driver.quit()

print(f"\n{'='*70}")
print("ë””ë²„ê¹… ì™„ë£Œ")
print("="*70)

print("\nğŸ’¡ ë¶„ì„:")
print("- ê° í˜ì´ì§€ì—ì„œ ê°™ì€ ê¸°ì‚¬ê°€ ë‚˜ì˜¨ë‹¤ë©´: í˜ì´ì§€ë„¤ì´ì…˜ì´ ì‘ë™í•˜ì§€ ì•ŠìŒ")
print("- ê° í˜ì´ì§€ì—ì„œ ë‹¤ë¥¸ ê¸°ì‚¬ê°€ ë‚˜ì˜¨ë‹¤ë©´: ì¤‘ë³µ ì œê±° ë¡œì§ ë¬¸ì œ")
print("- URLì´ ë¦¬ë‹¤ì´ë ‰íŠ¸ëœë‹¤ë©´: ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ í˜ì´ì§€ ì´ë™ í•„ìš”")








